{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08efd04f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete\n"
     ]
    }
   ],
   "source": [
    "# Setup and imports\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import re\n",
    "import string\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Text preprocessing\n",
    "import nltk\n",
    "try:\n",
    "    nltk.data.find('corpora/stopwords')\n",
    "except LookupError:\n",
    "    nltk.download('stopwords', quiet=True)\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "\n",
    "# Plot settings\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "print(\"Setup complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca3595b",
   "metadata": {},
   "source": [
    "### Step 1 : Load and Explore Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b637372f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading spam dataset...\n",
      "Dataset loaded: 5,508 emails\n",
      "Spam: 1,556 (28.2%)\n",
      "Ham: 3,952 (71.8%)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\r\\nSave up to 70% on Life Insurance.\\r\\nWhy S...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1) Fight The Risk of Cancer!\\r\\nhttp://www.adc...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1) Fight The Risk of Cancer!\\r\\nhttp://www.adc...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>##############################################...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I thought you might like these:\\r\\n1) Slim Dow...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  \\r\\nSave up to 70% on Life Insurance.\\r\\nWhy S...      1\n",
       "1  1) Fight The Risk of Cancer!\\r\\nhttp://www.adc...      1\n",
       "2  1) Fight The Risk of Cancer!\\r\\nhttp://www.adc...      1\n",
       "3  ##############################################...      1\n",
       "4  I thought you might like these:\\r\\n1) Slim Dow...      1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load dataset\n",
    "print(\"Loading spam dataset...\")\n",
    "df = pd.read_csv(\"Datasets/Spam_Ham_Dataset.csv\")\n",
    "\n",
    "# Clean data\n",
    "if 'Unnamed: 0' in df.columns:\n",
    "    df = df.drop('Unnamed: 0', axis=1)\n",
    "df.columns = ['text', 'label']\n",
    "\n",
    "# Remove empty emails\n",
    "df = df[df['text'].str.len() > 10]\n",
    "df = df[df['text'] != 'empty']\n",
    "df = df.dropna()\n",
    "\n",
    "print(f\"Dataset loaded: {len(df):,} emails\")\n",
    "print(f\"Spam: {sum(df['label']==1):,} ({sum(df['label']==1)/len(df)*100:.1f}%)\")\n",
    "print(f\"Ham: {sum(df['label']==0):,} ({sum(df['label']==0)/len(df)*100:.1f}%)\")\n",
    "\n",
    "# Show basic info\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa07389a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Emails:\n",
      "--------------------------------------------------\n",
      "\n",
      "SPAM Examples:\n",
      "1. \n",
      "Save up to 70% on Life Insurance.\n",
      "Why Spend More Than You Have To?Life Quote Savings\n",
      "Ensuring yo...\n",
      "2. 1) Fight The Risk of Cancer!\n",
      "http://www.adclick.ws/p.cfm?o=315&s=pk0072) Slim Down - Guaranteed to ...\n",
      "3. 1) Fight The Risk of Cancer!\n",
      "http://www.adclick.ws/p.cfm?o=315&s=pk0072) Slim Down - Guaranteed to ...\n",
      "\n",
      "HAM Examples:\n",
      "1.     Date:        Wed, 21 Aug 2002 10:54:46 -0500\n",
      "    From:        Chris Garrigues \n",
      "    Message-ID:...\n",
      "2. Martin A posted:\n",
      "Tassos Papadopoulos, the Greek sculptor behind the plan, judged that the\n",
      " limesto...\n",
      "3. Man Threatens Explosion In Moscow Thursday August 22, 2002 1:40 PM\n",
      "MOSCOW (AP) - Security officers ...\n"
     ]
    }
   ],
   "source": [
    "# Show sample emails\n",
    "print(\"Sample Emails:\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "print(\"\\nSPAM Examples:\")\n",
    "spam_samples = df[df['label'] == 1]['text'].head(3)\n",
    "for i, email in enumerate(spam_samples, 1):\n",
    "    print(f\"{i}. {email[:100]}...\")\n",
    "\n",
    "print(\"\\nHAM Examples:\")\n",
    "ham_samples = df[df['label'] == 0]['text'].head(3)\n",
    "for i, email in enumerate(ham_samples, 1):\n",
    "    print(f\"{i}. {email[:100]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2449d926",
   "metadata": {},
   "source": [
    "### Step 2: Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7cfbfb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing text...\n",
      "\n",
      "Preprocessing Example:\n",
      "Original: \n",
      "Save up to 70% on Life Insurance.\n",
      "Why Spend More Than You Have To?Life Quote Savings\n",
      "Ensuring your \n",
      "      family's financial security is very important. Life Quote Savings makes \n",
      "      buying li...\n",
      "Cleaned:  save life insurance spend tolife quote savings ensuring familys financial security important life quote savings makes buying life insurance simple affordable provide free access best companies lowest ...\n"
     ]
    }
   ],
   "source": [
    "# Text preprocessing function\n",
    "def preprocess_text(text):\n",
    "    \"\"\"\n",
    "    Clean email text for analysis.\n",
    "    \"\"\"\n",
    "    text = str(text).lower()\n",
    "    \n",
    "    # Remove URLs and email addresses\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text)\n",
    "    text = re.sub(r'\\S+@\\S+', '', text)\n",
    "    \n",
    "    # Remove HTML tags\n",
    "    text = re.sub(r'<.*?>', '', text)\n",
    "    \n",
    "    # Remove numbers and punctuation\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    \n",
    "    # Remove extra whitespace\n",
    "    text = ' '.join(text.split())\n",
    "    \n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = text.split()\n",
    "    words = [word for word in words if word not in stop_words and len(word) > 2]\n",
    "    \n",
    "    return ' '.join(words)\n",
    "\n",
    "# Preprocess all emails\n",
    "print(\"Preprocessing text...\")\n",
    "df['clean_text'] = df['text'].apply(preprocess_text)\n",
    "\n",
    "# Show preprocessing example\n",
    "sample_email = df['text'].iloc[0]\n",
    "cleaned_email = df['clean_text'].iloc[0]\n",
    "\n",
    "print(\"\\nPreprocessing Example:\")\n",
    "print(f\"Original: {sample_email[:200]}...\")\n",
    "print(f\"Cleaned:  {cleaned_email[:200]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dce3200",
   "metadata": {},
   "source": [
    "### Step 3: Feature Extraction and Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee7e84f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 5,000 emails for training\n",
      "Extracting TF-IDF features...\n",
      "Feature matrix: (5000, 5000)\n",
      "Training: 4,000 emails\n",
      "Testing: 1,000 emails\n"
     ]
    }
   ],
   "source": [
    "# Use subset for faster processing\n",
    "sample_size = 5000\n",
    "df_sample = df.sample(n=min(sample_size, len(df)), random_state=42)\n",
    "print(f\"Using {len(df_sample):,} emails for training\")\n",
    "\n",
    "# Extract TF-IDF features\n",
    "print(\"Extracting TF-IDF features...\")\n",
    "vectorizer = TfidfVectorizer(\n",
    "    max_features=5000,\n",
    "    ngram_range=(1, 2),\n",
    "    min_df=2,\n",
    "    max_df=0.8\n",
    ")\n",
    "\n",
    "X = vectorizer.fit_transform(df_sample['clean_text'])\n",
    "y = df_sample['label'].values\n",
    "\n",
    "print(f\"Feature matrix: {X.shape}\")\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Training: {X_train.shape[0]:,} emails\")\n",
    "print(f\"Testing: {X_test.shape[0]:,} emails\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (email-spam-detection)",
   "language": "python",
   "name": "email-spam-detection"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
